% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Bchronology.R
\name{Bchronology}
\alias{Bchronology}
\title{Runs the Compound Poisson-Gamma chronology model of Haslett and Parnell (2008)}
\usage{
Bchronology(
  ages,
  ageSds,
  positions,
  positionThicknesses = rep(0, length(ages)),
  calCurves = rep("intcal20", length(ages)),
  ids = NULL,
  outlierProbs = rep(0.01, length(ages)),
  predictPositions = seq(min(positions), max(positions), length = 100),
  pathToCalCurves = system.file("data", package = "Bchron"),
  artificialThickness = 0.01,
  allowOutside = FALSE,
  iterations = 10000,
  burn = 2000,
  thin = 8,
  extractDate = 1950 - as.numeric(format(Sys.time(), "\%Y")),
  maxExtrap = 1000,
  thetaStart = NULL,
  thetaMhSd = 0.5,
  muMhSd = 0.1,
  psiMhSd = 0.1,
  ageScaleVal = 1000,
  positionEps = 1e-05,
  positionNormalise = TRUE
)
}
\arguments{
\item{ages}{A vector of ages provided in years before 1950.}

\item{ageSds}{A vector of 1-sigma values for the ages given above}

\item{positions}{Position values (e.g. depths) for each age. In the case of layers of non-zero thickness, this should be the middle value of the slice}

\item{positionThicknesses}{Thickness values for each of the positions. The thickness value should be the full thickness value of the slice. By default set to zero.}

\item{calCurves}{A vector of values containing either \code{intcal20}, \code{shcal20}, \code{marine20}, or \code{normal} (older calibration curves are supposed such as intcal13). Should be the same length the number of ages supplied. Non-standard calibration curves can be used provided they are supplied in the same format as those previously mentioned and are placed in the same directory. Normal indicates a normally-distributed (non-14C) age.}

\item{ids}{ID names for each age}

\item{outlierProbs}{A vector of prior outlier probabilities, one for each age. Defaults to 0.01}

\item{predictPositions}{A vector of positions (e.g. depths) at which predicted age values are required. Defaults to a sequence of length 100 from the top position to the bottom position}

\item{pathToCalCurves}{File path to where the calibration curves are located. Defaults to the system directory where the 3 standard calibration curves are stored.}

\item{artificialThickness}{Amount to add to the thickness values in the case of equal positions with no \code{positionThicknesses}. Bchron may fail if \code{positionThicknesses} are zero and some positions are repeated. This value is added on to the zero thicknesses (only in the case of repeated positions) to stop this failure.}

\item{allowOutside}{Whether to allow calibrations to run outside the range of the calibration curve. By default this is turned off as calibrations outside of the range of the calibration curve can cause severe issues with probability ranges of calibrated dates}

\item{iterations}{The number of iterations to run the procedure for}

\item{burn}{The number of starting iterations to discard}

\item{thin}{The step size for every iteration to keep beyond the burn-in}

\item{extractDate}{The top age of the core. Used for extrapolation purposes so that no extrapolated ages go beyond the top age of the core. Defaults to the current year}

\item{maxExtrap}{The maximum number of extrapolations to perform before giving up and setting the predicted ages to NA. Useful for when large amounts of extrapolation are required, i.e. some of the \code{predictPositions} are a long way from the dated positions}

\item{thetaStart}{A set of starting values for the calendar ages estimated by Bchron. If NULL uses a function to estimate the ages. These should be in the same units as the posterior ages required. See example below for usage.}

\item{thetaMhSd}{The Metropolis-Hastings standard deviation for the age parameters}

\item{muMhSd}{The Metropolis-Hastings standard deviation for the Compound Poisson-Gamma mean}

\item{psiMhSd}{The Metropolis-Hastings standard deviation for the Compound Poisson-Gamma scale}

\item{ageScaleVal}{A scale value for the ages. \code{Bchronology} works best when the ages are scaled to be approximately between 0 and 100. The default value is thus 1000 for ages given in years.}

\item{positionEps}{A small value used to check whether simulated positions are far enough apart to avoid numerical underflow errors. If errors occur in model runs (e.g. \code{missing value where TRUE/FALSE needed} increase this value)}

\item{positionNormalise}{Whether to normalise the position values. \code{Bchronology} works best when the positions are normalised to be between 0 and 1 The default value is \code{TRUE}}
}
\value{
A list of class \code{BchronologyRun} which include elements:
 \item{theta}{The posterior estimated values of the ages}
 \item{phi}{The posterior estimated outlier values (1=outlier, 2=not outlier). The means of this parameter give the posterior estimated outlier probabilities}
 \item{mu}{The posterior values of the Compound Poisson-Gamma mean}
 \item{psi}{The posterior values of the Compound Poisson-Gamma scale}
 \item{thetaPredict}{The posterior estimated ages for each of the values in predictPosition}
 \item{predictPositions}{The positions at which estimated ages were required}
 \item{calAges}{The calibrated ages as output from \code{\link{BchronCalibrate}}}
 \item{inputVals}{All of the input values to the \code{Bchronology} run}
}
\description{
Fits a non-parametric chronology model to age/position data according to the Compound Poisson-Gamma model defined by Haslett and Parnell (2008) <DOI:10.1111/j.1467-9876.2008.00623.x>. This version uses a slightly modified Markov chain Monte Carlo fitting algorithm which aims to converge quicker and requires fewer iterations. It also a slightly modified procedure for identifying outliers
}
\details{
The \code{Bchronology} function fits a compound Poisson-Gamma distribution to the increments between the dated levels. This involves a stochastic linear interpolation step where the age gaps are Gamma distributed, and the position gaps are Exponential. Radiocarbon and non-radiocarbon dates (including outliers) are updated within the function also by MCMC.
}
\examples{
\donttest{
# Data from Glendalough
data(Glendalough)

# Run in Bchronology - all but first age uses intcal20
GlenOut <- with(
  Glendalough,
  Bchronology(
    ages = ages,
    ageSds = ageSds,
    calCurves = calCurves,
    positions = position,
    positionThicknesses = thickness,
    ids = id,
    predictPositions = seq(0, 1500, by = 10)
  )
)

# Summarise it a few different ways
summary(GlenOut) # Default is for quantiles of ages at predictPosition values
summary(GlenOut, type = "convergence") # Check model convergence
summary(GlenOut, type = "outliers") # Look at outlier probabilities

# Predict for some new positions
predictAges <- predict(GlenOut,
  newPositions = c(150, 725, 1500),
  newPositionThicknesses = c(5, 0, 20)
)

# Plot the output
plot(GlenOut) +
  ggplot2::labs(
    title = "Glendalough",
    xlab = "Age (cal years BP)",
    ylab = "Depth (cm)"
  )

# If you need to specify your own starting values
startingAges <- c(0, 2000, 10000, 11000, 13000, 13500)
GlenOut <- with(
  Glendalough,
  Bchronology(
    ages = ages,
    ageSds = ageSds,
    calCurves = calCurves,
    positions = position,
    positionThicknesses = thickness,
    ids = id,
    predictPositions = seq(0, 1500, by = 10),
    thetaStart = startingAges
  )
)
}

}
\references{
Haslett, J., and Parnell, A. C. (2008). A simple monotone process with application to radiocarbon-dated depth chronologies. Journal of the Royal Statistical Society, Series C, 57, 399-418. DOI:10.1111/j.1467-9876.2008.00623.x
Parnell, A. C., Haslett, J., Allen, J. R. M., Buck, C. E., and Huntley, B. (2008). A flexible approach to assessing synchroneity of past events using Bayesian reconstructions of sedimentation history. Quaternary Science Reviews, 27(19-20), 1872-1885. DOI:10.1016/j.quascirev.2008.07.009
}
\seealso{
\code{\link{BchronCalibrate}}, \code{\link{BchronRSL}}, \code{\link{BchronDensity}}, \code{\link{BchronDensityFast}}
}
